{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "TAVILY_API_KEY = os.environ[\"TAVILY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an expert about python coding\"),\n",
    "    (\"human\", \"Hey i need a python code to generate an cat image\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mchatModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:277\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    267\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    268\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    272\u001b[39m     **kwargs: Any,\n\u001b[32m    273\u001b[39m ) -> BaseMessage:\n\u001b[32m    274\u001b[39m     config = ensure_config(config)\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    276\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    287\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:777\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    769\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    771\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    774\u001b[39m     **kwargs: Any,\n\u001b[32m    775\u001b[39m ) -> LLMResult:\n\u001b[32m    776\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m777\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:634\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    632\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    633\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    635\u001b[39m flattened_outputs = [\n\u001b[32m    636\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    638\u001b[39m ]\n\u001b[32m    639\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:624\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    623\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m         )\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    632\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:846\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m846\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    850\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:589\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    587\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    590\u001b[39m     generation_info = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:929\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    888\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    926\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    927\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    928\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_base_client.py:1276\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1264\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1271\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1272\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1273\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1274\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1275\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_base_client.py:949\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_base_client.py:1042\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1041\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_base_client.py:1091\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1087\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1089\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_base_client.py:1042\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1041\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_base_client.py:1091\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1087\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1089\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/langgraph/lib/python3.11/site-packages/openai/_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1054\u001b[39m         err.response.read()\n\u001b[32m   1056\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1060\u001b[39m     cast_to=cast_to,\n\u001b[32m   1061\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1065\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1066\u001b[39m )\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "response = chatModel.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m.content)\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Groq models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an expert about python coding\"),\n",
    "    (\"human\", \"Hey i need a python code to generate an cat image\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a cat image using Python alone is a bit challenging, as Python is a programming language and not a graphics editor. However, we can use some libraries to generate a simple cat image using ASCII art or even create an image using Python's Pillow library.\n",
      "\n",
      "Here's an example of generating a simple cat image using ASCII art:\n",
      "```\n",
      "print(\" /_/\")\n",
      "print(\"( o.o )\")\n",
      "print(\" > ^ <\")\n",
      "```\n",
      "This will output a simple cat face using ASCII characters.\n",
      "\n",
      "If you want to generate a more complex image, we can use the Pillow library to create an image from scratch. Here's an example:\n",
      "```\n",
      "from PIL import Image, ImageDraw\n",
      "\n",
      "# Create a new image with a white background\n",
      "img = Image.new('RGB', (200, 200), color = (255, 255, 255))\n",
      "\n",
      "# Create a drawing object\n",
      "draw = ImageDraw.Draw(img)\n",
      "\n",
      "# Draw the cat's body\n",
      "draw.ellipse([(50, 50), (150, 150)], fill=(128, 128, 128), outline=(0, 0, 0))\n",
      "\n",
      "# Draw the cat's head\n",
      "draw.ellipse([(75, 75), (125, 125)], fill=(128, 128, 128), outline=(0, 0, 0))\n",
      "\n",
      "# Draw the cat's eyes\n",
      "draw.ellipse([(90, 90), (100, 100)], fill=(255, 255, 255), outline=(0, 0, 0))\n",
      "draw.ellipse([(110, 90), (120, 100)], fill=(255, 255, 255), outline=(0, 0, 0))\n",
      "\n",
      "# Draw the cat's nose\n",
      "draw.ellipse([(105, 105), (115, 115)], fill=(255, 0, 0), outline=(0, 0, 0))\n",
      "\n",
      "# Save the image to a file\n",
      "img.save('cat.png')\n",
      "```\n",
      "This code will generate a simple cat image with a gray body, white eyes, and a red nose. The resulting image will be saved as `cat.png` in the current working directory.\n",
      "\n",
      "Note that generating complex images using Python requires a good understanding of image processing and graphics. If you're looking to generate more complex images, you may want to consider using a dedicated graphics editor or a machine learning model specifically designed for image generation.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an expert\"),\n",
    "    (\"human\", \"tell me about 2025 LA wildfire updates\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, so I need to figure out what the 2025 LA wildfire updates are. I'm not exactly sure where to start, but I'll try to break it down. First, I know that wildfires in California, especially around LA, are a big deal every year. They usually happen in the summer and fall when it's hot and dry. But since I'm looking for information about 2025, which is in the future, I can't just look up current events. \\n\\nI guess I should think about the trends and factors that contribute to wildfires. Climate change is a big oneâ€”rising temperatures, droughts, and strong winds can all make wildfires worse. Maybe by 2025, these conditions have gotten more extreme. I've heard that climate models predict more frequent and intense wildfires in the future, so that could be a factor.\\n\\nAnother thing to consider is the vegetation in LA. If there's a lot of dry underbrush, that can fuel fires. Maybe by 2025, there have been more efforts in forest management, like controlled burns or clearing dead plants, which could help reduce the risk. But I'm not sure how effective those measures will be by then.\\n\\nI should also think about the weather patterns. Santa Ana winds are a major contributor to wildfires in LA. If those winds are stronger or more frequent in 2025, that could lead to more dangerous fire conditions. Plus, if there's a drought, the vegetation would be even drier and more susceptible to burning.\\n\\nTechnology might play a role too. Maybe by 2025, there are better systems for detecting wildfires early, using drones or satellites. Early detection can help contain fires before they get out of control. Also, firefighting techniques might have advanced, with more effective strategies to combat large fires.\\n\\nOn the flip side, population growth and urban sprawl could mean more people are living in fire-prone areas. That would put more lives and properties at risk. If there's been more development near wildlands without proper fire safety measures, that could exacerbate the problem.\\n\\nI wonder about the economic impact. Wildfires are expensive in terms of damage, firefighting costs, and health effects from smoke. By 2025, maybe there are new policies or insurance changes because of the increasing risk. Perhaps there's more emphasis on fire prevention and community preparedness.\\n\\nAnother angle is the environmental impact. Wildfires release a lot of carbon dioxide, which contributes to climate change. It's a vicious cycle. Also, the smoke from wildfires affects air quality and public health, so by 2025, maybe there are more stringent regulations or public health measures in place to mitigate those effects.\\n\\nI should also consider any new infrastructure. Maybe fire breaks or green belts have been built around LA to prevent fires from spreading into urban areas. Or perhaps there are more fire stations and emergency response plans in place.\\n\\nI'm not sure about the specific events of 2025, though. It's possible that there could have been a particularly bad wildfire season that year, maybe even record-breaking in terms of size or destruction. Alternatively, maybe 2025 was a relatively calm year if there were favorable weather conditions or successful prevention measures.\\n\\nI should also think about any policy changes or government responses. Maybe by 2025, there's a new federal or state program aimed at wildfire prevention and management. This could include funding for forest management, research into fire-resistant materials, or community education on fire safety.\\n\\nLastly, I can't ignore the human element. How are communities preparing? Maybe by 2025, there's a greater emphasis on building fire-resistant homes, creating defensible spaces around properties, and having evacuation plans in place.\\n\\nPutting this all together, I think the 2025 LA wildfire updates would likely include a mix of challenges and advancements. On one hand, the conditions for wildfires might be worse due to climate change, but on the other hand, there could be better technologies and strategies in place to manage and prevent them. It's a balance between the increasing risk factors and the efforts to mitigate those risks.\\n</think>\\n\\nThe 2025 LA wildfire updates are likely to reflect a complex interplay of challenges and advancements. Here's a structured overview:\\n\\n1. **Climate and Weather Factors:**\\n   - **Climate Change Impact:** Increased temperatures and drought conditions may exacerbate wildfire risks, with more frequent and intense fires.\\n   - **Santa Ana Winds:** Potentially stronger or more frequent winds could heighten fire danger, especially during dry conditions.\\n\\n2. **Vegetation and Land Management:**\\n   - **Forest Management Efforts:** Enhanced strategies like controlled burns and vegetation clearing might be in place to reduce fuel for fires, though effectiveness may vary.\\n\\n3. **Technological Advancements:**\\n   - **Early Detection:** Improved systems using drones and satellites could lead to quicker identification and containment of fires.\\n   - **Firefighting Techniques:** More effective strategies and technologies might be employed to combat large-scale fires.\\n\\n4. **Urban Development and Risk:**\\n   - **Urban Sprawl:** Increased development in wildland-urban interfaces could elevate risk, necessitating better fire safety measures.\\n\\n5. **Economic and Policy Implications:**\\n   - **Economic Impact:** Potential rise in costs related to damage, firefighting, and health effects, possibly leading to new insurance policies and prevention emphasis.\\n   - **Policy Changes:** New programs or funding for forest management, fire-resistant materials, and community education.\\n\\n6. **Environmental and Health Considerations:**\\n   - **Carbon Emissions and Air Quality:** Increased awareness of wildfire contributions to climate change and air quality issues, possibly leading to stricter regulations.\\n   - **Public Health Measures:** Enhanced strategies to mitigate smoke effects on health.\\n\\n7. **Infrastructure and Community Preparedness:**\\n   - **Fire Prevention Infrastructure:** Possible implementation of fire breaks or green belts around urban areas.\\n   - **Community Preparedness:** Greater emphasis on fire-resistant construction, defensible spaces, and evacuation plans.\\n\\n8. **Potential Scenarios:**\\n   - **Severe Fire Season:** Possibility of record-breaking fires due to adverse conditions.\\n   - **Successful Mitigation:** Favorable weather or effective prevention could result in a calmer season.\\n\\nIn summary, while 2025 may see heightened wildfire risks due to climate factors, advancements in technology, policy, and community preparedness could mitigate these challenges, offering a balanced outlook between risk and resilience.\", response_metadata={'token_usage': {'completion_tokens': 1304, 'prompt_tokens': 17, 'total_tokens': 1321, 'completion_time': 4.741818182, 'prompt_time': 0.003896679, 'queue_time': 0.045895081, 'total_time': 4.745714861}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-766738d0-e07a-4a87-9f53-07ed124f7499-0', usage_metadata={'input_tokens': 17, 'output_tokens': 1304, 'total_tokens': 1321})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out what the 2025 LA wildfire updates are. I'm not exactly sure where to start, but I'll try to break it down. First, I know that wildfires in California, especially around LA, are a big deal every year. They usually happen in the summer and fall when it's hot and dry. But since I'm looking for information about 2025, which is in the future, I can't just look up current events. \n",
      "\n",
      "I guess I should think about the trends and factors that contribute to wildfires. Climate change is a big oneâ€”rising temperatures, droughts, and strong winds can all make wildfires worse. Maybe by 2025, these conditions have gotten more extreme. I've heard that climate models predict more frequent and intense wildfires in the future, so that could be a factor.\n",
      "\n",
      "Another thing to consider is the vegetation in LA. If there's a lot of dry underbrush, that can fuel fires. Maybe by 2025, there have been more efforts in forest management, like controlled burns or clearing dead plants, which could help reduce the risk. But I'm not sure how effective those measures will be by then.\n",
      "\n",
      "I should also think about the weather patterns. Santa Ana winds are a major contributor to wildfires in LA. If those winds are stronger or more frequent in 2025, that could lead to more dangerous fire conditions. Plus, if there's a drought, the vegetation would be even drier and more susceptible to burning.\n",
      "\n",
      "Technology might play a role too. Maybe by 2025, there are better systems for detecting wildfires early, using drones or satellites. Early detection can help contain fires before they get out of control. Also, firefighting techniques might have advanced, with more effective strategies to combat large fires.\n",
      "\n",
      "On the flip side, population growth and urban sprawl could mean more people are living in fire-prone areas. That would put more lives and properties at risk. If there's been more development near wildlands without proper fire safety measures, that could exacerbate the problem.\n",
      "\n",
      "I wonder about the economic impact. Wildfires are expensive in terms of damage, firefighting costs, and health effects from smoke. By 2025, maybe there are new policies or insurance changes because of the increasing risk. Perhaps there's more emphasis on fire prevention and community preparedness.\n",
      "\n",
      "Another angle is the environmental impact. Wildfires release a lot of carbon dioxide, which contributes to climate change. It's a vicious cycle. Also, the smoke from wildfires affects air quality and public health, so by 2025, maybe there are more stringent regulations or public health measures in place to mitigate those effects.\n",
      "\n",
      "I should also consider any new infrastructure. Maybe fire breaks or green belts have been built around LA to prevent fires from spreading into urban areas. Or perhaps there are more fire stations and emergency response plans in place.\n",
      "\n",
      "I'm not sure about the specific events of 2025, though. It's possible that there could have been a particularly bad wildfire season that year, maybe even record-breaking in terms of size or destruction. Alternatively, maybe 2025 was a relatively calm year if there were favorable weather conditions or successful prevention measures.\n",
      "\n",
      "I should also think about any policy changes or government responses. Maybe by 2025, there's a new federal or state program aimed at wildfire prevention and management. This could include funding for forest management, research into fire-resistant materials, or community education on fire safety.\n",
      "\n",
      "Lastly, I can't ignore the human element. How are communities preparing? Maybe by 2025, there's a greater emphasis on building fire-resistant homes, creating defensible spaces around properties, and having evacuation plans in place.\n",
      "\n",
      "Putting this all together, I think the 2025 LA wildfire updates would likely include a mix of challenges and advancements. On one hand, the conditions for wildfires might be worse due to climate change, but on the other hand, there could be better technologies and strategies in place to manage and prevent them. It's a balance between the increasing risk factors and the efforts to mitigate those risks.\n",
      "</think>\n",
      "\n",
      "The 2025 LA wildfire updates are likely to reflect a complex interplay of challenges and advancements. Here's a structured overview:\n",
      "\n",
      "1. **Climate and Weather Factors:**\n",
      "   - **Climate Change Impact:** Increased temperatures and drought conditions may exacerbate wildfire risks, with more frequent and intense fires.\n",
      "   - **Santa Ana Winds:** Potentially stronger or more frequent winds could heighten fire danger, especially during dry conditions.\n",
      "\n",
      "2. **Vegetation and Land Management:**\n",
      "   - **Forest Management Efforts:** Enhanced strategies like controlled burns and vegetation clearing might be in place to reduce fuel for fires, though effectiveness may vary.\n",
      "\n",
      "3. **Technological Advancements:**\n",
      "   - **Early Detection:** Improved systems using drones and satellites could lead to quicker identification and containment of fires.\n",
      "   - **Firefighting Techniques:** More effective strategies and technologies might be employed to combat large-scale fires.\n",
      "\n",
      "4. **Urban Development and Risk:**\n",
      "   - **Urban Sprawl:** Increased development in wildland-urban interfaces could elevate risk, necessitating better fire safety measures.\n",
      "\n",
      "5. **Economic and Policy Implications:**\n",
      "   - **Economic Impact:** Potential rise in costs related to damage, firefighting, and health effects, possibly leading to new insurance policies and prevention emphasis.\n",
      "   - **Policy Changes:** New programs or funding for forest management, fire-resistant materials, and community education.\n",
      "\n",
      "6. **Environmental and Health Considerations:**\n",
      "   - **Carbon Emissions and Air Quality:** Increased awareness of wildfire contributions to climate change and air quality issues, possibly leading to stricter regulations.\n",
      "   - **Public Health Measures:** Enhanced strategies to mitigate smoke effects on health.\n",
      "\n",
      "7. **Infrastructure and Community Preparedness:**\n",
      "   - **Fire Prevention Infrastructure:** Possible implementation of fire breaks or green belts around urban areas.\n",
      "   - **Community Preparedness:** Greater emphasis on fire-resistant construction, defensible spaces, and evacuation plans.\n",
      "\n",
      "8. **Potential Scenarios:**\n",
      "   - **Severe Fire Season:** Possibility of record-breaking fires due to adverse conditions.\n",
      "   - **Successful Mitigation:** Favorable weather or effective prevention could result in a calmer season.\n",
      "\n",
      "In summary, while 2025 may see heightened wildfire risks due to climate factors, advancements in technology, policy, and community preparedness could mitigate these challenges, offering a balanced outlook between risk and resilience.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tavily Search test Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.facebook.com/deccannews/videos/on-march-5-2025-a-landslide-in-chamoli-district-uttarakhand-led-to-the-collapse-/1143288827071074/',\n",
       "  'content': 'On March 5, 2025, a landslide in #Chamoli district, #Uttarakhand led to the collapse of a suspension motor bridge that connected #Govindghat to #hemkundsahib .'},\n",
       " {'url': 'https://www.aljazeera.com/news/2025/2/28/avalanche-traps-42-workers-under-snow-near-india-tibet-border',\n",
       "  'content': 'An avalanche struck a GREF Camp near Mana village in Garhwal Sector. A number of labourers are feared to be trapped. Indian Armyâ€™s IBEX BRIGADE swiftly launched rescue operations inspite of continuing heavy snowfall and minor avalanches. So far 10â€¦ pic.twitter.com/adVcAu9g4g\\n\\nâ€” SuryaCommand_IA (@suryacommand) February 28, 2025\\n\\n\\n\\nAvalanches and landslides are common in the upper reaches of the Himalayas. [...] â€œIt has been snowing with strong winds. â€¦ The roads are completely blocked. We have deployed snow cutters to open the road,â€ he told broadcaster NDTV.\\n\\nRidhim Agarwal of the state disaster relief force said high-altitude rescue teams will be deployed by helicopter to the scene once the weather improves. [...] Five of the containers have been located, the statement said, and the search for the remaining three was ongoing.\\n\\nAt least 32 workers had been rescued, Chamoli District Administrator Sandeep Tiwari told the news agency ANI on Friday evening, and there was no indication of any casualties.\\n\\nStrong winds and snowfall, however, were hampering the rescue operations, Deepam Seth, the stateâ€™s top police officer, said.'},\n",
       " {'url': 'https://ulmmc.in/',\n",
       "  'content': 'The Himalayan region and especially the state of Uttarakhand has a past history of several landslide disaster events which took heavy toll on lives and'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search = TavilySearchResults(max_results=3)\n",
    "search.invoke(\"tell me about the landslides incidents in Uttarakhand,India in 2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TavilySearchResults(max_results=3)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [search]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='tell me about the landslides incidents in Uttarakhand,India in 2025', id='6fb016ce-12c0-4bbb-9680-1960031afa7e'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0xyw', 'function': {'arguments': '{\"query\":\"landslides in Uttarakhand, India 2025\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 224, 'prompt_tokens': 177, 'total_tokens': 401, 'completion_time': 0.814545455, 'prompt_time': 0.011937284, 'queue_time': 0.051277434000000004, 'total_time': 0.826482739}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-035c6247-ba0c-430f-b078-87afe089935d-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'landslides in Uttarakhand, India 2025'}, 'id': 'call_0xyw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 224, 'total_tokens': 401}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.facebook.com/deccannews/videos/on-march-5-2025-a-landslide-in-chamoli-district-uttarakhand-led-to-the-collapse-/1143288827071074/\", \"content\": \"On March 5, 2025, a landslide in #Chamoli district, #Uttarakhand led to the collapse of a suspension motor bridge that connected #Govindghat to #hemkundsahib .\"}, {\"url\": \"https://www.aljazeera.com/news/2025/2/28/avalanche-traps-42-workers-under-snow-near-india-tibet-border\", \"content\": \"An avalanche struck a GREF Camp near Mana village in Garhwal Sector. A number of labourers are feared to be trapped. Indian Armyâ€™s IBEX BRIGADE swiftly launched rescue operations inspite of continuing heavy snowfall and minor avalanches. So far 10â€¦ pic.twitter.com/adVcAu9g4g\\\\n\\\\nâ€” SuryaCommand_IA (@suryacommand) February 28, 2025\\\\n\\\\n\\\\n\\\\nAvalanches and landslides are common in the upper reaches of the Himalayas.\"}, {\"url\": \"https://www.indiatvnews.com/news/india/uttarakhand-reels-under-heavy-rain-landslides-and-flash-floods-severe-damage-across-state-watch-2025-04-10-984828\", \"content\": \"Â© 2009-2025 Independent News Service. All rights reserved. [...] Uttarakhand reels under heavy rain, landslides and flash floods, severe damage across state | WATCH\\\\n\\\\nUttarakhand is facing severe weather conditions with heavy rainfall, landslides, flash floods, hailstorms, and widespread damage to infrastructure, leading to major disruptions and ongoing rescue operations. [...] Rescue operations on high alert\\\\n\\\\nLocal authorities, including the police and administration, have gone into active mode, with rescue and relief teams on high alert. They have been instructed to remain vigilant as they assess the damage and begin relief efforts. Several regions, especially in the higher reaches of Uttarakhand, have seen their roads blocked by landslides, making it difficult for residents and emergency services to access impacted areas.\"}]', name='tavily_search_results_json', id='3f486e08-22f7-4351-9531-9b9a60c8ff7f', tool_call_id='call_0xyw'),\n",
       "  AIMessage(content=\"In 2025, Uttarakhand, India experienced several significant landslide incidents that caused considerable damage and disruption. \\n\\n1. **March 5, 2025**: A landslide occurred in the Chamoli district, leading to the collapse of a suspension bridge that connected Govindghat to Hemkundsahib. This incident disrupted transportation in the area and highlighted the region's susceptibility to such events.\\n\\n2. **February 28, 2025**: An avalanche struck near the India-Tibet border, trapping 42 workers. The Indian Army's IBEX BRIGADE conducted rescue operations despite challenging conditions, including ongoing snowfall and minor avalanches. This incident underscored the risks faced by laborers in remote, high-altitude regions.\\n\\n3. **April 2025**: Heavy rainfall caused widespread landslides and flash floods across Uttarakhand. These events led to severe infrastructure damage, with many roads blocked, hindering access for both residents and emergency services. Local authorities were on high alert, conducting rescue and relief operations to address the crisis.\\n\\nThese incidents illustrate Uttarakhand's vulnerability to natural disasters, exacerbated by its geographical location in the Himalayas, where such events are common. The state faced significant challenges in managing the impacts of these landslides and avalanches, emphasizing the need for preparedness and robust disaster management strategies.\", response_metadata={'token_usage': {'completion_tokens': 519, 'prompt_tokens': 723, 'total_tokens': 1242, 'completion_time': 1.887272727, 'prompt_time': 0.045976766, 'queue_time': 0.09135258499999999, 'total_time': 1.933249493}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd5dc472-969e-483b-a43c-f618b914a826-0', usage_metadata={'input_tokens': 723, 'output_tokens': 519, 'total_tokens': 1242})]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"tell me about the landslides incidents in Uttarakhand,India in 2025\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"In 2025, Uttarakhand, India experienced several significant landslide incidents that caused considerable damage and disruption. \\n\\n1. **March 5, 2025**: A landslide occurred in the Chamoli district, leading to the collapse of a suspension bridge that connected Govindghat to Hemkundsahib. This incident disrupted transportation in the area and highlighted the region's susceptibility to such events.\\n\\n2. **February 28, 2025**: An avalanche struck near the India-Tibet border, trapping 42 workers. The Indian Army's IBEX BRIGADE conducted rescue operations despite challenging conditions, including ongoing snowfall and minor avalanches. This incident underscored the risks faced by laborers in remote, high-altitude regions.\\n\\n3. **April 2025**: Heavy rainfall caused widespread landslides and flash floods across Uttarakhand. These events led to severe infrastructure damage, with many roads blocked, hindering access for both residents and emergency services. Local authorities were on high alert, conducting rescue and relief operations to address the crisis.\\n\\nThese incidents illustrate Uttarakhand's vulnerability to natural disasters, exacerbated by its geographical location in the Himalayas, where such events are common. The state faced significant challenges in managing the impacts of these landslides and avalanches, emphasizing the need for preparedness and robust disaster management strategies.\" response_metadata={'token_usage': {'completion_tokens': 519, 'prompt_tokens': 723, 'total_tokens': 1242, 'completion_time': 1.887272727, 'prompt_time': 0.045976766, 'queue_time': 0.09135258499999999, 'total_time': 1.933249493}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None} id='run-dd5dc472-969e-483b-a43c-f618b914a826-0' usage_metadata={'input_tokens': 723, 'output_tokens': 519, 'total_tokens': 1242}\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding memory\n",
    "* Adding memory in LangGraph is very similar to what we did with LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hs20', 'function': {'arguments': '{\"query\":\"2024 Eurocup winner\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 252, 'prompt_tokens': 169, 'total_tokens': 421, 'completion_time': 0.916363636, 'prompt_time': 0.009634935, 'queue_time': 0.049024601, 'total_time': 0.925998571}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cc72b53c-8156-457f-93c9-8b3af51d5cd5-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '2024 Eurocup winner'}, 'id': 'call_hs20', 'type': 'tool_call'}], usage_metadata={'input_tokens': 169, 'output_tokens': 252, 'total_tokens': 421})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.business-standard.com/sports/football-news/european-championship-winners-runner-ups-list-2024-champion-s-prize-money-124071400688_1.html\", \"content\": \"Spain won its 4th Uefa European Championships title in history as it beat England 2-1 in the Euro Cup 2024 final on July 15 (Indian time).\"}, {\"url\": \"https://www.cnn.com/2024/07/14/sport/spain-england-euro-2024-final-spt-intl/index.html\", \"content\": \"CNN values your feedback\\\\n\\\\nSpain wins Euro 2024, defeating England 2-1 in a dramatic final to claim record fourth European Championship\\\\n\\\\nFollow:\\\\n\\\\nSpain won a record-breaking fourth European Championship, defeating England 2-1 following a drama-filled second half in the Euro 2024 final on Sunday in Berlin. [...] England had become renowned for late heroics at Euro 2024, and the squad needed yet another moment of magic if it had any hopes of getting back into the game.\\\\n\\\\nAs the clock hit 90 minutes, a corner was headed towards goal by Declan Rice, with SimÃ³n parrying it out to Guehi whose effort was cleared off the line by RB Leipzig man Dani Olmo as Spainâ€™s defense celebrated thwarting another English attack. [...] â€œAlthough victory may have eluded you this evening, nevertheless my wife and I join all my family in urging you and your support team to hold your heads high. All those who have participated in sporting activities at any level will know how utterly despairing such a result can feel when the prize was so near â€“ and will join me in sending heartfelt sympathy, even as we congratulate Spain.\"}, {\"url\": \"https://www.youtube.com/watch?v=jPG0J8PrrrQ\", \"content\": \"Euro Cup 2024 final highlights: Spain wins record 4th title with a 2-1 victory against England Â· Comments1.\"}]', name='tavily_search_results_json', tool_call_id='call_hs20')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=\"The winner of the 2024 soccer Eurocup was **Spain**, who defeated England 2-1 in the final. This victory marked Spain's record-breaking fourth European Championship title.\", response_metadata={'token_usage': {'completion_tokens': 271, 'prompt_tokens': 651, 'total_tokens': 922, 'completion_time': 0.985454545, 'prompt_time': 0.036830969, 'queue_time': 0.046062686, 'total_time': 1.022285514}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-ee8c3a69-8ae8-4278-a43f-15a0edc081a6-0', usage_metadata={'input_tokens': 651, 'output_tokens': 271, 'total_tokens': 922})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Who won the 2024 soccer Eurocup?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"The top stars of Spain's 2024 Eurocup-winning team included players who made significant contributions to their success. While specific standout performers may vary depending on individual highlights, some key players likely played pivotal roles:\\n\\n1. **Pedri**: A dynamic and creative midfielder known for his exceptional control and ability to dictate the flow of the game.\\n\\n2. **Gavi**: A young and energetic midfielder who brought relentless energy and tenacity to the team, often breaking up play and initiating attacks.\\n\\n3. **Dani Olmo**: A versatile attacker with the ability to create chances and score crucial goals, making him a standout in the tournament.\\n\\n4. **Marco Asensio**: A skilled forward who contributed with both goals and assists, playing a key role in Spain's offensive efforts.\\n\\n5. **Unai SimÃ³n**: The goalkeeper who made crucial saves throughout the tournament, securing Spain's victories and keeping them in contention during high-pressure moments.\\n\\nThese players, among others, were instrumental in leading Spain to their record-breaking fourth European Championship title.\", response_metadata={'token_usage': {'completion_tokens': 450, 'prompt_tokens': 974, 'total_tokens': 1424, 'completion_time': 1.636363636, 'prompt_time': 0.043411825, 'queue_time': 0.074541116, 'total_time': 1.679775461}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-ce046d65-f201-4851-864a-938ae90ec01b-0', usage_metadata={'input_tokens': 974, 'output_tokens': 450, 'total_tokens': 1424})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Who were the top stars of that winner team?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"Based on the available highlights and the context provided, here is a list of standout players from Spain's 2024 Eurocup-winning team:\\n\\n1. **Dani Olmo**  \\n   - Played a crucial role in the final, making key plays and even clearing a shot off the line to secure the victory.\\n\\n2. **Pedri**  \\n   - A dynamic midfielder who controlled the tempo of the game and was instrumental in Spain's possession-based style.\\n\\n3. **Gavi**  \\n   - A young and energetic midfielder who brought tenacity and creativity to the team.\\n\\n4. **Jordi Alba**  \\n   - A consistent and experienced defender who supported both defense and attack effectively.\\n\\n5. **Unai SimÃ³n**  \\n   - The goalkeeper who made critical saves throughout the tournament, including in the final.\\n\\n6. **Marco Asensio**  \\n   - A skilled attacker who contributed to Spain's offensive efforts with goals and assists.\\n\\n7. **Joselu**  \\n   - A forward who scored important goals during the tournament.\\n\\n8. **Rodri**  \\n   - A solid presence in midfield, contributing to both defense and attack.\\n\\nThis list is based on the available highlights and may not include every standout performer, as individual brilliance can vary depending on specific moments in the tournament.\", response_metadata={'token_usage': {'completion_tokens': 525, 'prompt_tokens': 1196, 'total_tokens': 1721, 'completion_time': 1.9090909090000001, 'prompt_time': 0.047418731, 'queue_time': 0.052735869, 'total_time': 1.9565096400000002}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-f8119fe3-5539-4850-be84-4288295d8eac-0', usage_metadata={'input_tokens': 1196, 'output_tokens': 525, 'total_tokens': 1721})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"list down the names of the best player of that season\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pzbf', 'function': {'arguments': '{\"query\":\"who hit the maximum goals in the final\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 169, 'total_tokens': 309, 'completion_time': 0.509090909, 'prompt_time': 0.010094827, 'queue_time': 0.050175303, 'total_time': 0.519185736}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b302de04-2263-4038-920b-669f2b629997-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'who hit the maximum goals in the final'}, 'id': 'call_pzbf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 169, 'output_tokens': 140, 'total_tokens': 309})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.statmuse.com/nhl/ask/nhl-team-most-goal-in-a-game-in-stanley-cup-final\", \"content\": \"The Vegas Golden Knights, the Toronto Maple Leafs and the Detroit Red Wings are tied for the most goals in a Stanley Cup Finals game, with 9 scored. [...] Central Division | W | L | OTL | PTS | DIFF\\\\nJets | 56 | 22 | 4 | 116 | 86\\\\nStars | 50 | 26 | 6 | 106 | 53\\\\nAvalanche | 49 | 29 | 4 | 102 | 43\\\\nPacific Division | W | L | OTL | PTS | DIFF\\\\nGolden Knights | 50 | 22 | 10 | 110 | 56\\\\nKings | 48 | 25 | 9 | 105 | 44\\\\nOilers | 48 | 29 | 5 | 101 | 23\\\\nAtlantic Division | W | L | OTL | PTS | DIFF\\\\nMaple Leafs | 52 | 26 | 4 | 108 | 37\\\\nLightning | 47 | 27 | 8 | 102 | 75\\\\nPanthers | 47 | 31 | 4 | 98 | 29\\\\nMetropolitan Division | W | L | OTL | PTS | DIFF [...] 16 |  | Bruins | 7 | 6/1/2019 | 2018-19 | Stanley Cup Finals | BOS | @ | STL | W7-2 | 2 | 4 | 4 | 1 | 5 | 24 | 29\\\\n17 |  | Blackhawks | 7 | 6/6/2010 | 2009-10 | Stanley Cup Finals | CHI | vs | PHI | W7-4 | 4 | 2 | 4 | 0 | 3 | 28 | 27\\\\n18 |  | Devils | 7 | 5/30/2000 | 1999-00 | Stanley Cup Finals | NJD | vs | DAL | W7-3 | 3 | 1 | 4 | 0 | 0 | 26 | 18\\\\n19 |  | Oilers | 7 | 5/18/1990 | 1989-90 | Stanley Cup Finals | EDM | @ | BOS | W7-2 | 2 | 2 | 3 | 1 | 5 | 22 | 27\"}, {\"url\": \"https://m.allfootballapp.com/news/All/5-players-who-have-scored-the-most-goals-in-finals/2874711\", \"content\": \"Without further ado, let\\'s take a look at the five players who have scored the most goals in finals.\\\\n\\\\n#5 Romario - 19 goals\\\\n\\\\n\\\\n\\\\nRomario de Souza Faria is widely regarded as one of the greatest strikers of all time. He is one of the all-time top goalscorers in the history of the beautiful game, having found the back of the net 755 times in his senior career. [...] Just like Neymar surpassed Cristiano Ronaldo last night with his brace against Nantes, Messi overtook Pele to sit at the top of the list. The 35-year-old opened the scoring for Paris Saint-Germain in their 4-0 win over Nantes in the Trophees des Champions final.\\\\n\\\\nMessi has now scored a whopping 32 goals in finals in his career. That\\'s a GOAT level accomplishment without a doubt.\\\\n\\\\nCopyright Declaration [...] Ronaldo is a great example of a player who thrives under pressure. The Manchester United forward leads from the front in high-pressure scenarios and this is a trait that has propelled him to greatness. The legendary Portuguese forward has scored 20 goals in finals so far in his career.\\\\n\\\\n#3 Neymar Jr. - 21 goals\"}, {\"url\": \"https://www.quora.com/Has-anyone-ever-scored-five-goals-in-a-single-FIFA-World-Cup-Final\", \"content\": \"The highest number of goals scored by a player in a World Cup Final match is four, achieved by Geoff Hurst of England in 1966. His hat-trick\"}]', name='tavily_search_results_json', tool_call_id='call_pzbf')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=\"Based on the search results, it appears you're asking about the player who scored the most goals in a final. According to the information:\\n\\n- **Lionel Messi** has scored the most goals in finals with **32 goals** in his career.\\n- Other notable players include **Cristiano Ronaldo** with 20 goals in finals and **Neymar Jr.** with 21 goals.\\n\\nIf you're referring to a specific final, such as the FIFA World Cup Final, the record for the most goals scored in a single World Cup Final is **4 goals**, achieved by **Geoff Hurst** of England in 1966.\", response_metadata={'token_usage': {'completion_tokens': 439, 'prompt_tokens': 1131, 'total_tokens': 1570, 'completion_time': 1.596363636, 'prompt_time': 0.056587386, 'queue_time': 0.04767044799999999, 'total_time': 1.6529510219999999}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-4b6bbc9a-9f46-469f-9789-683fc2c7caf0-0', usage_metadata={'input_tokens': 1131, 'output_tokens': 439, 'total_tokens': 1570})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"002\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"who hit the maximum goals in the final? \")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='The tool outputs do not specify the individual goal scorers in the final. For detailed information about the goal scorers, you would need to refer to the full match reports or official sources covering the 2024 Eurocup final.', response_metadata={'token_usage': {'completion_tokens': 319, 'prompt_tokens': 1471, 'total_tokens': 1790, 'completion_time': 1.16, 'prompt_time': 0.066986088, 'queue_time': 0.048241132000000006, 'total_time': 1.226986088}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-40e68cd0-a0c1-4885-98c5-96be5a0ab984-0', usage_metadata={'input_tokens': 1471, 'output_tokens': 319, 'total_tokens': 1790})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"001\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"who hit the maximum goals in the final? \")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
